{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wfHKLXRKYQm",
        "outputId": "fa23aff8-6b79-4474-995a-c080e9f1f820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas Dataset"
      ],
      "metadata": {
        "id": "4h6r1GVlLGp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "AzIDSlVsKac1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/high_senior_result.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0FBAFYz8sdy_",
        "outputId": "937909aa-e31c-4f5d-c0dd-b1a5e3765a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  student_id  problem_id  curriculum_id        name  problem_cr   result  \\\n",
              "0    I100008      508171             21       확률의 뜻    0.632113  CORRECT   \n",
              "1    I100008      399004             21       확률의 뜻   -0.557984  CORRECT   \n",
              "2    I100008      508131             17    확률의 곱셈정리    0.171439  CORRECT   \n",
              "3    I100008      399631             15  사건의 독립과 종속    1.454540  CORRECT   \n",
              "4    I100008      399781              7      연속확률변수   -2.632940    WRONG   \n",
              "\n",
              "   level  type  avg_cr  o_cr  x_cr      update_datetime  \n",
              "0      2     0      63    65    57  2021-01-04 11:40:50  \n",
              "1      4     2      63    65    57  2021-01-04 11:40:50  \n",
              "2      3     0      63    65    57  2021-01-04 11:40:50  \n",
              "3      2     0      63    65    57  2021-01-04 11:40:50  \n",
              "4      4     2      63    65    57  2021-01-04 11:40:50  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff50a4a1-630a-445d-8e5e-0ae8a78f3249\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>problem_id</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>name</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "      <th>level</th>\n",
              "      <th>type</th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>update_datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I100008</td>\n",
              "      <td>508171</td>\n",
              "      <td>21</td>\n",
              "      <td>확률의 뜻</td>\n",
              "      <td>0.632113</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I100008</td>\n",
              "      <td>399004</td>\n",
              "      <td>21</td>\n",
              "      <td>확률의 뜻</td>\n",
              "      <td>-0.557984</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I100008</td>\n",
              "      <td>508131</td>\n",
              "      <td>17</td>\n",
              "      <td>확률의 곱셈정리</td>\n",
              "      <td>0.171439</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I100008</td>\n",
              "      <td>399631</td>\n",
              "      <td>15</td>\n",
              "      <td>사건의 독립과 종속</td>\n",
              "      <td>1.454540</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I100008</td>\n",
              "      <td>399781</td>\n",
              "      <td>7</td>\n",
              "      <td>연속확률변수</td>\n",
              "      <td>-2.632940</td>\n",
              "      <td>WRONG</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff50a4a1-630a-445d-8e5e-0ae8a78f3249')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff50a4a1-630a-445d-8e5e-0ae8a78f3249 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff50a4a1-630a-445d-8e5e-0ae8a78f3249');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## datetime 활용\n",
        "2020, 2021 데이터 활용해서 훈련\n",
        "(2022는 finetuning 활용?)"
      ],
      "metadata": {
        "id": "cJTLRHa2uaKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['update_datetime'] = pd.to_datetime(df['update_datetime'])"
      ],
      "metadata": {
        "id": "d8veeavYtg9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['update_year'] = df['update_datetime'].dt.year\n",
        "df['update_month'] = df['update_datetime'].dt.month\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_y_tvbPmt4p_",
        "outputId": "f603d6b0-842a-40b1-b002-be3a28c62e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        student_id  problem_id  curriculum_id        name  problem_cr  \\\n",
              "0          I100008      508171             21       확률의 뜻    0.632113   \n",
              "1          I100008      399004             21       확률의 뜻   -0.557984   \n",
              "2          I100008      508131             17    확률의 곱셈정리    0.171439   \n",
              "3          I100008      399631             15  사건의 독립과 종속    1.454540   \n",
              "4          I100008      399781              7      연속확률변수   -2.632940   \n",
              "...            ...         ...            ...         ...         ...   \n",
              "3265550     I99685      446377              9        정규분포    0.978203   \n",
              "3265551     I99685      400841              9        정규분포   -0.869958   \n",
              "3265552     I99685      511458              9        정규분포    0.019666   \n",
              "3265553     I99685      508537              9        정규분포   -0.019859   \n",
              "3265554     I99685      400734              9        정규분포   -2.121800   \n",
              "\n",
              "          result  level  type  avg_cr  o_cr  x_cr     update_datetime  \\\n",
              "0        CORRECT      2     0      63    65    57 2021-01-04 11:40:50   \n",
              "1        CORRECT      4     2      63    65    57 2021-01-04 11:40:50   \n",
              "2        CORRECT      3     0      63    65    57 2021-01-04 11:40:50   \n",
              "3        CORRECT      2     0      63    65    57 2021-01-04 11:40:50   \n",
              "4          WRONG      4     2      63    65    57 2021-01-04 11:40:50   \n",
              "...          ...    ...   ...     ...   ...   ...                 ...   \n",
              "3265550    WRONG      3     0      63    69    58 2021-06-17 20:34:53   \n",
              "3265551    WRONG      3     2      63    69    58 2021-06-17 20:34:53   \n",
              "3265552    WRONG      3     0      63    69    58 2021-06-17 20:34:53   \n",
              "3265553    WRONG      3     0      63    69    58 2021-06-17 20:34:53   \n",
              "3265554    WRONG      4     2      63    69    58 2021-06-17 20:34:53   \n",
              "\n",
              "         update_year  update_month  \n",
              "0               2021             1  \n",
              "1               2021             1  \n",
              "2               2021             1  \n",
              "3               2021             1  \n",
              "4               2021             1  \n",
              "...              ...           ...  \n",
              "3265550         2021             6  \n",
              "3265551         2021             6  \n",
              "3265552         2021             6  \n",
              "3265553         2021             6  \n",
              "3265554         2021             6  \n",
              "\n",
              "[3265555 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d6104ce-f1f0-4a46-bfea-b998a1ebb072\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>problem_id</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>name</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "      <th>level</th>\n",
              "      <th>type</th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>update_datetime</th>\n",
              "      <th>update_year</th>\n",
              "      <th>update_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I100008</td>\n",
              "      <td>508171</td>\n",
              "      <td>21</td>\n",
              "      <td>확률의 뜻</td>\n",
              "      <td>0.632113</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I100008</td>\n",
              "      <td>399004</td>\n",
              "      <td>21</td>\n",
              "      <td>확률의 뜻</td>\n",
              "      <td>-0.557984</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I100008</td>\n",
              "      <td>508131</td>\n",
              "      <td>17</td>\n",
              "      <td>확률의 곱셈정리</td>\n",
              "      <td>0.171439</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I100008</td>\n",
              "      <td>399631</td>\n",
              "      <td>15</td>\n",
              "      <td>사건의 독립과 종속</td>\n",
              "      <td>1.454540</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I100008</td>\n",
              "      <td>399781</td>\n",
              "      <td>7</td>\n",
              "      <td>연속확률변수</td>\n",
              "      <td>-2.632940</td>\n",
              "      <td>WRONG</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265550</th>\n",
              "      <td>I99685</td>\n",
              "      <td>446377</td>\n",
              "      <td>9</td>\n",
              "      <td>정규분포</td>\n",
              "      <td>0.978203</td>\n",
              "      <td>WRONG</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>2021-06-17 20:34:53</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265551</th>\n",
              "      <td>I99685</td>\n",
              "      <td>400841</td>\n",
              "      <td>9</td>\n",
              "      <td>정규분포</td>\n",
              "      <td>-0.869958</td>\n",
              "      <td>WRONG</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>2021-06-17 20:34:53</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265552</th>\n",
              "      <td>I99685</td>\n",
              "      <td>511458</td>\n",
              "      <td>9</td>\n",
              "      <td>정규분포</td>\n",
              "      <td>0.019666</td>\n",
              "      <td>WRONG</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>2021-06-17 20:34:53</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265553</th>\n",
              "      <td>I99685</td>\n",
              "      <td>508537</td>\n",
              "      <td>9</td>\n",
              "      <td>정규분포</td>\n",
              "      <td>-0.019859</td>\n",
              "      <td>WRONG</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>2021-06-17 20:34:53</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265554</th>\n",
              "      <td>I99685</td>\n",
              "      <td>400734</td>\n",
              "      <td>9</td>\n",
              "      <td>정규분포</td>\n",
              "      <td>-2.121800</td>\n",
              "      <td>WRONG</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>2021-06-17 20:34:53</td>\n",
              "      <td>2021</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3265555 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d6104ce-f1f0-4a46-bfea-b998a1ebb072')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d6104ce-f1f0-4a46-bfea-b998a1ebb072 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d6104ce-f1f0-4a46-bfea-b998a1ebb072');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['update_year'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-aJU9hIuFtO",
        "outputId": "8f47d32d-fea7-4eb7-e6ea-c26ad7040484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2021, 2022, 2020])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_use = df[df['update_year'] != 2022]\n",
        "df_use.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ffuTYqFnuQOy",
        "outputId": "4818ecfc-a6e6-4120-aa72-eea2cf21651b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  student_id  problem_id  curriculum_id        name  problem_cr   result  \\\n",
              "0    I100008      508171             21       확률의 뜻    0.632113  CORRECT   \n",
              "1    I100008      399004             21       확률의 뜻   -0.557984  CORRECT   \n",
              "2    I100008      508131             17    확률의 곱셈정리    0.171439  CORRECT   \n",
              "3    I100008      399631             15  사건의 독립과 종속    1.454540  CORRECT   \n",
              "4    I100008      399781              7      연속확률변수   -2.632940    WRONG   \n",
              "\n",
              "   level  type  avg_cr  o_cr  x_cr     update_datetime  update_year  \\\n",
              "0      2     0      63    65    57 2021-01-04 11:40:50         2021   \n",
              "1      4     2      63    65    57 2021-01-04 11:40:50         2021   \n",
              "2      3     0      63    65    57 2021-01-04 11:40:50         2021   \n",
              "3      2     0      63    65    57 2021-01-04 11:40:50         2021   \n",
              "4      4     2      63    65    57 2021-01-04 11:40:50         2021   \n",
              "\n",
              "   update_month  \n",
              "0             1  \n",
              "1             1  \n",
              "2             1  \n",
              "3             1  \n",
              "4             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0d10a87-f8b9-4409-ada7-491a404b3902\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>problem_id</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>name</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "      <th>level</th>\n",
              "      <th>type</th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>update_datetime</th>\n",
              "      <th>update_year</th>\n",
              "      <th>update_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I100008</td>\n",
              "      <td>508171</td>\n",
              "      <td>21</td>\n",
              "      <td>확률의 뜻</td>\n",
              "      <td>0.632113</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I100008</td>\n",
              "      <td>399004</td>\n",
              "      <td>21</td>\n",
              "      <td>확률의 뜻</td>\n",
              "      <td>-0.557984</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I100008</td>\n",
              "      <td>508131</td>\n",
              "      <td>17</td>\n",
              "      <td>확률의 곱셈정리</td>\n",
              "      <td>0.171439</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I100008</td>\n",
              "      <td>399631</td>\n",
              "      <td>15</td>\n",
              "      <td>사건의 독립과 종속</td>\n",
              "      <td>1.454540</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I100008</td>\n",
              "      <td>399781</td>\n",
              "      <td>7</td>\n",
              "      <td>연속확률변수</td>\n",
              "      <td>-2.632940</td>\n",
              "      <td>WRONG</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-01-04 11:40:50</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0d10a87-f8b9-4409-ada7-491a404b3902')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0d10a87-f8b9-4409-ada7-491a404b3902 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0d10a87-f8b9-4409-ada7-491a404b3902');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2022 = df[df['update_year'] == 2022]\n",
        "df_2022.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zk8TDFPiIrzK",
        "outputId": "d2672bfa-0ba4-4c24-a8ac-d5c83a84b3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    student_id  problem_id  curriculum_id            name  problem_cr  \\\n",
              "847    I100067      584855             33  지수함수와 로그함수의 미분    0.043118   \n",
              "848    I100067      435439             33  지수함수와 로그함수의 미분   -0.164510   \n",
              "849    I100067      580450             33  지수함수와 로그함수의 미분   -0.010880   \n",
              "850    I100067      513317             33  지수함수와 로그함수의 미분    0.103597   \n",
              "851    I100067      435503             33  지수함수와 로그함수의 미분   -0.784152   \n",
              "\n",
              "      result  level  type  avg_cr  o_cr  x_cr     update_datetime  \\\n",
              "847  CORRECT      3     2      62    64    51 2022-01-10 18:49:52   \n",
              "848  CORRECT      3     0      62    64    51 2022-01-10 18:49:52   \n",
              "849  CORRECT      3     2      62    64    51 2022-01-10 18:49:52   \n",
              "850  CORRECT      3     0      62    64    51 2022-01-10 18:49:52   \n",
              "851  CORRECT      3     0      62    64    51 2022-01-10 18:49:52   \n",
              "\n",
              "     update_year  update_month  \n",
              "847         2022             1  \n",
              "848         2022             1  \n",
              "849         2022             1  \n",
              "850         2022             1  \n",
              "851         2022             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b27d9310-1bcf-4d3a-986c-a2b5bf0d3a4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>problem_id</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>name</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "      <th>level</th>\n",
              "      <th>type</th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>update_datetime</th>\n",
              "      <th>update_year</th>\n",
              "      <th>update_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>I100067</td>\n",
              "      <td>584855</td>\n",
              "      <td>33</td>\n",
              "      <td>지수함수와 로그함수의 미분</td>\n",
              "      <td>0.043118</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>2022-01-10 18:49:52</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>I100067</td>\n",
              "      <td>435439</td>\n",
              "      <td>33</td>\n",
              "      <td>지수함수와 로그함수의 미분</td>\n",
              "      <td>-0.164510</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>2022-01-10 18:49:52</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>I100067</td>\n",
              "      <td>580450</td>\n",
              "      <td>33</td>\n",
              "      <td>지수함수와 로그함수의 미분</td>\n",
              "      <td>-0.010880</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>2022-01-10 18:49:52</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>I100067</td>\n",
              "      <td>513317</td>\n",
              "      <td>33</td>\n",
              "      <td>지수함수와 로그함수의 미분</td>\n",
              "      <td>0.103597</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>2022-01-10 18:49:52</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851</th>\n",
              "      <td>I100067</td>\n",
              "      <td>435503</td>\n",
              "      <td>33</td>\n",
              "      <td>지수함수와 로그함수의 미분</td>\n",
              "      <td>-0.784152</td>\n",
              "      <td>CORRECT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>2022-01-10 18:49:52</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b27d9310-1bcf-4d3a-986c-a2b5bf0d3a4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b27d9310-1bcf-4d3a-986c-a2b5bf0d3a4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b27d9310-1bcf-4d3a-986c-a2b5bf0d3a4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_2022 = df_2022[['avg_cr', 'o_cr', 'x_cr', 'curriculum_id', 'type', 'problem_cr', 'result']]\n",
        "df_2022"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_LlrFk4kIx3G",
        "outputId": "18a675ea-a603-494a-b552-6317e1630b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         avg_cr  o_cr  x_cr  curriculum_id  type  problem_cr   result\n",
              "847          62    64    51             33     2    0.043118  CORRECT\n",
              "848          62    64    51             33     0   -0.164510  CORRECT\n",
              "849          62    64    51             33     2   -0.010880  CORRECT\n",
              "850          62    64    51             33     0    0.103597  CORRECT\n",
              "851          62    64    51             33     0   -0.784152  CORRECT\n",
              "...         ...   ...   ...            ...   ...         ...      ...\n",
              "3258186      70    71    66             18     0    0.969386    WRONG\n",
              "3258187      70    71    66             18     0    0.990076    WRONG\n",
              "3258188      70    71    66              9     0    0.575786  CORRECT\n",
              "3258189      70    71    66             13     0    0.101836    WRONG\n",
              "3258190      70    71    66             44     0   -1.727930    WRONG\n",
              "\n",
              "[1306890 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3f7740e-6329-4f66-9116-db6e64b7aa7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>type</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>0.043118</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.164510</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.010880</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0.103597</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851</th>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>51</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.784152</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258186</th>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>66</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.969386</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258187</th>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>66</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.990076</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258188</th>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>66</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.575786</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258189</th>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>66</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0.101836</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258190</th>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>66</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.727930</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1306890 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3f7740e-6329-4f66-9116-db6e64b7aa7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3f7740e-6329-4f66-9116-db6e64b7aa7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3f7740e-6329-4f66-9116-db6e64b7aa7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_use)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kpyMdm2ushH",
        "outputId": "c2d9271b-5133-434e-e7c8-91c31b41c591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1958665"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_use = df_use[['avg_cr', 'o_cr', 'x_cr', 'curriculum_id', 'type', 'problem_cr', 'result']]\n",
        "df_use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Fpej_kW6s9pj",
        "outputId": "75f267c1-2e07-4d4f-c8f3-3139887565fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         avg_cr  o_cr  x_cr  curriculum_id  type  problem_cr   result\n",
              "0            63    65    57             21     0    0.632113  CORRECT\n",
              "1            63    65    57             21     2   -0.557984  CORRECT\n",
              "2            63    65    57             17     0    0.171439  CORRECT\n",
              "3            63    65    57             15     0    1.454540  CORRECT\n",
              "4            63    65    57              7     2   -2.632940    WRONG\n",
              "...         ...   ...   ...            ...   ...         ...      ...\n",
              "3265550      63    69    58              9     0    0.978203    WRONG\n",
              "3265551      63    69    58              9     2   -0.869958    WRONG\n",
              "3265552      63    69    58              9     0    0.019666    WRONG\n",
              "3265553      63    69    58              9     0   -0.019859    WRONG\n",
              "3265554      63    69    58              9     2   -2.121800    WRONG\n",
              "\n",
              "[1958665 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1b7bfb1-52ec-4d2a-a4ac-e9c85d2573cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>type</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.632113</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.557984</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.171439</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1.454540</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.632940</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265550</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.978203</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265551</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.869958</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265552</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.019666</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265553</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.019859</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265554</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.121800</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1958665 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1b7bfb1-52ec-4d2a-a4ac-e9c85d2573cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1b7bfb1-52ec-4d2a-a4ac-e9c85d2573cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1b7bfb1-52ec-4d2a-a4ac-e9c85d2573cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## correct가 wrong보다 많긴함 (일단 처리 안하고 ㄲ)"
      ],
      "metadata": {
        "id": "eoU51uk6yx7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_use[df_use['result'] == 'CORRECT'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XklFPan7yclq",
        "outputId": "3b15bc31-470d-451e-8e69-ba1064d21e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1465570"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_use[df_use['result'] == 'WRONG'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNh31Xhhynfw",
        "outputId": "4a55fffe-9c89-47dd-a16d-5155ca7ed0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "493095"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_use"
      ],
      "metadata": {
        "id": "R23kyWsQySej",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ee08ef86-0977-4840-eba1-78226d09ae65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         avg_cr  o_cr  x_cr  curriculum_id  type  problem_cr   result\n",
              "0            63    65    57             21     0    0.632113  CORRECT\n",
              "1            63    65    57             21     2   -0.557984  CORRECT\n",
              "2            63    65    57             17     0    0.171439  CORRECT\n",
              "3            63    65    57             15     0    1.454540  CORRECT\n",
              "4            63    65    57              7     2   -2.632940    WRONG\n",
              "...         ...   ...   ...            ...   ...         ...      ...\n",
              "3265550      63    69    58              9     0    0.978203    WRONG\n",
              "3265551      63    69    58              9     2   -0.869958    WRONG\n",
              "3265552      63    69    58              9     0    0.019666    WRONG\n",
              "3265553      63    69    58              9     0   -0.019859    WRONG\n",
              "3265554      63    69    58              9     2   -2.121800    WRONG\n",
              "\n",
              "[1958665 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b39f810-f6d6-475f-a863-99a0f3db29e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>type</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.632113</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.557984</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.171439</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1.454540</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.632940</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265550</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.978203</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265551</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.869958</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265552</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.019666</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265553</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.019859</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265554</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.121800</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1958665 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b39f810-f6d6-475f-a863-99a0f3db29e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b39f810-f6d6-475f-a863-99a0f3db29e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b39f810-f6d6-475f-a863-99a0f3db29e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_index_list = list(df_use[df_use['result']=='CORRECT'].index)\n",
        "correct_index_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c36WduSDwHch",
        "outputId": "430087fe-e4d4-46fe-b2f8-6283bbd6758d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 30,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 77,\n",
              " 84,\n",
              " 85,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 102,\n",
              " 103,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 110,\n",
              " 111,\n",
              " 113,\n",
              " 115,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 121,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 125,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 139,\n",
              " 140,\n",
              " 141,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 161,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 179,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 199,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 235,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 253,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 277,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 284,\n",
              " 289,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 305,\n",
              " 306,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 330,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 339,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 354,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 365,\n",
              " 366,\n",
              " 367,\n",
              " 368,\n",
              " 369,\n",
              " 370,\n",
              " 371,\n",
              " 373,\n",
              " 374,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 378,\n",
              " 379,\n",
              " 380,\n",
              " 381,\n",
              " 382,\n",
              " 383,\n",
              " 385,\n",
              " 386,\n",
              " 387,\n",
              " 390,\n",
              " 392,\n",
              " 393,\n",
              " 394,\n",
              " 395,\n",
              " 396,\n",
              " 398,\n",
              " 400,\n",
              " 401,\n",
              " 402,\n",
              " 403,\n",
              " 404,\n",
              " 405,\n",
              " 407,\n",
              " 408,\n",
              " 409,\n",
              " 410,\n",
              " 411,\n",
              " 412,\n",
              " 413,\n",
              " 414,\n",
              " 415,\n",
              " 416,\n",
              " 417,\n",
              " 418,\n",
              " 419,\n",
              " 421,\n",
              " 422,\n",
              " 423,\n",
              " 424,\n",
              " 425,\n",
              " 426,\n",
              " 427,\n",
              " 428,\n",
              " 429,\n",
              " 430,\n",
              " 432,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 437,\n",
              " 438,\n",
              " 440,\n",
              " 441,\n",
              " 442,\n",
              " 443,\n",
              " 444,\n",
              " 445,\n",
              " 446,\n",
              " 447,\n",
              " 448,\n",
              " 449,\n",
              " 450,\n",
              " 451,\n",
              " 452,\n",
              " 453,\n",
              " 454,\n",
              " 455,\n",
              " 456,\n",
              " 457,\n",
              " 459,\n",
              " 460,\n",
              " 461,\n",
              " 462,\n",
              " 463,\n",
              " 465,\n",
              " 466,\n",
              " 467,\n",
              " 468,\n",
              " 469,\n",
              " 470,\n",
              " 471,\n",
              " 475,\n",
              " 476,\n",
              " 477,\n",
              " 478,\n",
              " 482,\n",
              " 485,\n",
              " 490,\n",
              " 491,\n",
              " 497,\n",
              " 499,\n",
              " 500,\n",
              " 505,\n",
              " 507,\n",
              " 508,\n",
              " 509,\n",
              " 510,\n",
              " 513,\n",
              " 514,\n",
              " 515,\n",
              " 516,\n",
              " 517,\n",
              " 518,\n",
              " 519,\n",
              " 520,\n",
              " 522,\n",
              " 523,\n",
              " 524,\n",
              " 525,\n",
              " 526,\n",
              " 527,\n",
              " 528,\n",
              " 529,\n",
              " 530,\n",
              " 532,\n",
              " 533,\n",
              " 534,\n",
              " 535,\n",
              " 538,\n",
              " 539,\n",
              " 541,\n",
              " 543,\n",
              " 544,\n",
              " 545,\n",
              " 546,\n",
              " 547,\n",
              " 548,\n",
              " 553,\n",
              " 554,\n",
              " 556,\n",
              " 557,\n",
              " 558,\n",
              " 559,\n",
              " 560,\n",
              " 563,\n",
              " 567,\n",
              " 568,\n",
              " 569,\n",
              " 570,\n",
              " 571,\n",
              " 572,\n",
              " 573,\n",
              " 574,\n",
              " 575,\n",
              " 577,\n",
              " 579,\n",
              " 580,\n",
              " 581,\n",
              " 583,\n",
              " 584,\n",
              " 586,\n",
              " 588,\n",
              " 589,\n",
              " 591,\n",
              " 592,\n",
              " 593,\n",
              " 594,\n",
              " 595,\n",
              " 596,\n",
              " 600,\n",
              " 602,\n",
              " 603,\n",
              " 604,\n",
              " 605,\n",
              " 606,\n",
              " 607,\n",
              " 608,\n",
              " 609,\n",
              " 611,\n",
              " 612,\n",
              " 613,\n",
              " 614,\n",
              " 615,\n",
              " 616,\n",
              " 617,\n",
              " 621,\n",
              " 622,\n",
              " 623,\n",
              " 624,\n",
              " 627,\n",
              " 628,\n",
              " 629,\n",
              " 631,\n",
              " 633,\n",
              " 634,\n",
              " 635,\n",
              " 636,\n",
              " 637,\n",
              " 640,\n",
              " 643,\n",
              " 644,\n",
              " 645,\n",
              " 646,\n",
              " 650,\n",
              " 651,\n",
              " 652,\n",
              " 653,\n",
              " 654,\n",
              " 655,\n",
              " 657,\n",
              " 658,\n",
              " 660,\n",
              " 661,\n",
              " 662,\n",
              " 663,\n",
              " 664,\n",
              " 666,\n",
              " 667,\n",
              " 668,\n",
              " 669,\n",
              " 670,\n",
              " 671,\n",
              " 672,\n",
              " 674,\n",
              " 676,\n",
              " 677,\n",
              " 678,\n",
              " 679,\n",
              " 680,\n",
              " 681,\n",
              " 682,\n",
              " 683,\n",
              " 686,\n",
              " 687,\n",
              " 688,\n",
              " 690,\n",
              " 691,\n",
              " 692,\n",
              " 694,\n",
              " 695,\n",
              " 696,\n",
              " 697,\n",
              " 698,\n",
              " 699,\n",
              " 700,\n",
              " 701,\n",
              " 702,\n",
              " 703,\n",
              " 704,\n",
              " 705,\n",
              " 706,\n",
              " 707,\n",
              " 708,\n",
              " 709,\n",
              " 710,\n",
              " 711,\n",
              " 714,\n",
              " 715,\n",
              " 716,\n",
              " 718,\n",
              " 719,\n",
              " 720,\n",
              " 721,\n",
              " 722,\n",
              " 723,\n",
              " 724,\n",
              " 725,\n",
              " 726,\n",
              " 727,\n",
              " 728,\n",
              " 729,\n",
              " 730,\n",
              " 731,\n",
              " 732,\n",
              " 733,\n",
              " 734,\n",
              " 735,\n",
              " 736,\n",
              " 737,\n",
              " 738,\n",
              " 739,\n",
              " 740,\n",
              " 741,\n",
              " 742,\n",
              " 743,\n",
              " 744,\n",
              " 745,\n",
              " 746,\n",
              " 747,\n",
              " 748,\n",
              " 749,\n",
              " 750,\n",
              " 751,\n",
              " 752,\n",
              " 753,\n",
              " 754,\n",
              " 755,\n",
              " 756,\n",
              " 757,\n",
              " 758,\n",
              " 759,\n",
              " 760,\n",
              " 761,\n",
              " 763,\n",
              " 764,\n",
              " 765,\n",
              " 766,\n",
              " 767,\n",
              " 768,\n",
              " 769,\n",
              " 770,\n",
              " 771,\n",
              " 772,\n",
              " 773,\n",
              " 774,\n",
              " 775,\n",
              " 776,\n",
              " 777,\n",
              " 778,\n",
              " 779,\n",
              " 780,\n",
              " 781,\n",
              " 782,\n",
              " 783,\n",
              " 784,\n",
              " 785,\n",
              " 788,\n",
              " 789,\n",
              " 790,\n",
              " 791,\n",
              " 792,\n",
              " 793,\n",
              " 794,\n",
              " 795,\n",
              " 796,\n",
              " 797,\n",
              " 798,\n",
              " 799,\n",
              " 801,\n",
              " 802,\n",
              " 803,\n",
              " 804,\n",
              " 805,\n",
              " 806,\n",
              " 807,\n",
              " 808,\n",
              " 810,\n",
              " 811,\n",
              " 812,\n",
              " 813,\n",
              " 814,\n",
              " 815,\n",
              " 816,\n",
              " 820,\n",
              " 821,\n",
              " 822,\n",
              " 823,\n",
              " 824,\n",
              " 826,\n",
              " 827,\n",
              " 828,\n",
              " 829,\n",
              " 831,\n",
              " 832,\n",
              " 833,\n",
              " 834,\n",
              " 835,\n",
              " 837,\n",
              " 838,\n",
              " 839,\n",
              " 840,\n",
              " 841,\n",
              " 842,\n",
              " 843,\n",
              " 844,\n",
              " 845,\n",
              " 846,\n",
              " 1470,\n",
              " 1471,\n",
              " 1472,\n",
              " 1474,\n",
              " 1476,\n",
              " 1477,\n",
              " 1478,\n",
              " 1479,\n",
              " 1480,\n",
              " 1481,\n",
              " 1482,\n",
              " 1483,\n",
              " 1484,\n",
              " 1485,\n",
              " 1486,\n",
              " 1487,\n",
              " 1488,\n",
              " 1489,\n",
              " 1491,\n",
              " 1492,\n",
              " 1494,\n",
              " 1495,\n",
              " 1496,\n",
              " 1497,\n",
              " 1498,\n",
              " 1499,\n",
              " 1500,\n",
              " 1501,\n",
              " 1502,\n",
              " 1503,\n",
              " 1504,\n",
              " 1505,\n",
              " 1506,\n",
              " 1507,\n",
              " 1508,\n",
              " 1509,\n",
              " 1510,\n",
              " 1511,\n",
              " 1512,\n",
              " 1513,\n",
              " 1514,\n",
              " 1515,\n",
              " 1516,\n",
              " 1517,\n",
              " 1518,\n",
              " 1519,\n",
              " 1520,\n",
              " 1522,\n",
              " 1523,\n",
              " 1524,\n",
              " 1525,\n",
              " 1526,\n",
              " 1527,\n",
              " 1528,\n",
              " 1529,\n",
              " 1530,\n",
              " 1531,\n",
              " 1532,\n",
              " 1533,\n",
              " 1534,\n",
              " 1538,\n",
              " 1539,\n",
              " 1540,\n",
              " 1541,\n",
              " 1542,\n",
              " 1544,\n",
              " 1545,\n",
              " 1546,\n",
              " 1547,\n",
              " 1548,\n",
              " 1549,\n",
              " 1551,\n",
              " 1552,\n",
              " 1554,\n",
              " 1559,\n",
              " 1561,\n",
              " 1563,\n",
              " 1564,\n",
              " 1566,\n",
              " 1567,\n",
              " 1568,\n",
              " 1569,\n",
              " 1571,\n",
              " 1573,\n",
              " 1575,\n",
              " 1576,\n",
              " 1577,\n",
              " 1578,\n",
              " 1579,\n",
              " 1581,\n",
              " 1582,\n",
              " 1584,\n",
              " 1585,\n",
              " 1587,\n",
              " 1588,\n",
              " 1591,\n",
              " 1592,\n",
              " 1594,\n",
              " 1595,\n",
              " 1597,\n",
              " 1599,\n",
              " 1600,\n",
              " 1601,\n",
              " 1603,\n",
              " 1605,\n",
              " 1606,\n",
              " 1607,\n",
              " 1608,\n",
              " 1609,\n",
              " 1611,\n",
              " 1612,\n",
              " 1613,\n",
              " 1615,\n",
              " 1619,\n",
              " 1620,\n",
              " 1622,\n",
              " 1624,\n",
              " 1626,\n",
              " 1628,\n",
              " 1629,\n",
              " 1632,\n",
              " 1633,\n",
              " 1634,\n",
              " 1636,\n",
              " 1637,\n",
              " 1638,\n",
              " 1640,\n",
              " 1641,\n",
              " 1642,\n",
              " 1643,\n",
              " 1644,\n",
              " 1645,\n",
              " 1646,\n",
              " 1647,\n",
              " 1648,\n",
              " 1655,\n",
              " 1660,\n",
              " 1661,\n",
              " 1666,\n",
              " 1667,\n",
              " 1668,\n",
              " 1669,\n",
              " 1671,\n",
              " 1672,\n",
              " 1673,\n",
              " 1676,\n",
              " 1678,\n",
              " 1679,\n",
              " 1681,\n",
              " 1684,\n",
              " 1685,\n",
              " 1686,\n",
              " 1687,\n",
              " 1690,\n",
              " 1691,\n",
              " 1692,\n",
              " 1693,\n",
              " 1694,\n",
              " 1696,\n",
              " 1697,\n",
              " 1698,\n",
              " 1703,\n",
              " 1704,\n",
              " 1705,\n",
              " 1706,\n",
              " 1707,\n",
              " 1709,\n",
              " 1712,\n",
              " 1713,\n",
              " 1714,\n",
              " 1715,\n",
              " 1718,\n",
              " 1719,\n",
              " 1722,\n",
              " 1723,\n",
              " 1724,\n",
              " 1725,\n",
              " 1727,\n",
              " 1728,\n",
              " 1730,\n",
              " 1731,\n",
              " 1733,\n",
              " 1734,\n",
              " 1735,\n",
              " 1737,\n",
              " 1738,\n",
              " 1739,\n",
              " 1742,\n",
              " 1743,\n",
              " 1746,\n",
              " 1747,\n",
              " 1748,\n",
              " 1749,\n",
              " 1750,\n",
              " 1754,\n",
              " 1755,\n",
              " 1756,\n",
              " 1757,\n",
              " 1758,\n",
              " 1761,\n",
              " 1762,\n",
              " 1765,\n",
              " 1767,\n",
              " 1769,\n",
              " 1771,\n",
              " 1772,\n",
              " 1774,\n",
              " 1775,\n",
              " 1776,\n",
              " 1777,\n",
              " 1778,\n",
              " 1779,\n",
              " 1780,\n",
              " 1781,\n",
              " 1782,\n",
              " 1783,\n",
              " 1784,\n",
              " 1785,\n",
              " 1791,\n",
              " 1792,\n",
              " 1793,\n",
              " 1794,\n",
              " 1796,\n",
              " 1797,\n",
              " 1798,\n",
              " 1799,\n",
              " 1801,\n",
              " 1803,\n",
              " 1804,\n",
              " 1806,\n",
              " 1808,\n",
              " 1814,\n",
              " 1822,\n",
              " 1823,\n",
              " 1824,\n",
              " 1829,\n",
              " 1830,\n",
              " 1832,\n",
              " 1833,\n",
              " 1834,\n",
              " 1835,\n",
              " 1836,\n",
              " 1837,\n",
              " 1838,\n",
              " 1839,\n",
              " 1840,\n",
              " 1841,\n",
              " 1842,\n",
              " 1843,\n",
              " 1844,\n",
              " 1847,\n",
              " 1849,\n",
              " 1850,\n",
              " 1851,\n",
              " 1852,\n",
              " 1853,\n",
              " 1855,\n",
              " 1856,\n",
              " 1857,\n",
              " 1859,\n",
              " 1860,\n",
              " 1861,\n",
              " 1863,\n",
              " 1865,\n",
              " 1866,\n",
              " 1867,\n",
              " 1868,\n",
              " 1869,\n",
              " 1870,\n",
              " 1871,\n",
              " 1873,\n",
              " 1874,\n",
              " 1875,\n",
              " 1876,\n",
              " 1877,\n",
              " 1878,\n",
              " 1879,\n",
              " 1880,\n",
              " 1881,\n",
              " 1882,\n",
              " 1883,\n",
              " 1884,\n",
              " 1885,\n",
              " 1889,\n",
              " 1890,\n",
              " 1892,\n",
              " 1893,\n",
              " 1894,\n",
              " 1897,\n",
              " 1898,\n",
              " 1899,\n",
              " 1901,\n",
              " 1902,\n",
              " 1903,\n",
              " 1904,\n",
              " 1905,\n",
              " 1906,\n",
              " 1907,\n",
              " 1909,\n",
              " 1910,\n",
              " 1913,\n",
              " 1915,\n",
              " 1916,\n",
              " 1919,\n",
              " 1920,\n",
              " 1921,\n",
              " 1922,\n",
              " 1923,\n",
              " 1924,\n",
              " 1925,\n",
              " 1926,\n",
              " 1927,\n",
              " 1928,\n",
              " 1929,\n",
              " 1930,\n",
              " 1931,\n",
              " 1932,\n",
              " 1934,\n",
              " 1935,\n",
              " 1936,\n",
              " 1937,\n",
              " 1938,\n",
              " 1940,\n",
              " 1945,\n",
              " 1947,\n",
              " 1948,\n",
              " 1950,\n",
              " 1952,\n",
              " 1954,\n",
              " 1955,\n",
              " 1956,\n",
              " 1957,\n",
              " 1958,\n",
              " 1959,\n",
              " 1960,\n",
              " 1961,\n",
              " 1962,\n",
              " 1964,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "correct_index_list_sampled = random.sample(correct_index_list, 1000000)"
      ],
      "metadata": {
        "id": "tBWztGGxwew7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_use = df_use.loc[~df_use.index.isin(correct_index_list_sampled)]\n",
        "df_use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "b4P2-4Zlw2Qe",
        "outputId": "a99153aa-9c30-4d11-a692-6d48361fe172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         avg_cr  o_cr  x_cr  curriculum_id  type  problem_cr   result\n",
              "2            63    65    57             17     0    0.171439  CORRECT\n",
              "4            63    65    57              7     2   -2.632940    WRONG\n",
              "5            63    65    57              6     0   -1.111420    WRONG\n",
              "6            63    65    57             10     0   -0.832890  CORRECT\n",
              "7            63    65    57              9     2   -1.317680  CORRECT\n",
              "...         ...   ...   ...            ...   ...         ...      ...\n",
              "3265550      63    69    58              9     0    0.978203    WRONG\n",
              "3265551      63    69    58              9     2   -0.869958    WRONG\n",
              "3265552      63    69    58              9     0    0.019666    WRONG\n",
              "3265553      63    69    58              9     0   -0.019859    WRONG\n",
              "3265554      63    69    58              9     2   -2.121800    WRONG\n",
              "\n",
              "[958665 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4473e8f-7573-4f67-b2ea-bc428c626bbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>type</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.171439</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.632940</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.111420</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.832890</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.317680</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265550</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.978203</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265551</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.869958</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265552</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.019666</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265553</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.019859</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3265554</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.121800</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>958665 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4473e8f-7573-4f67-b2ea-bc428c626bbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4473e8f-7573-4f67-b2ea-bc428c626bbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4473e8f-7573-4f67-b2ea-bc428c626bbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_use[df_use['result'] == 'CORRECT'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xk8drATxG_s",
        "outputId": "1b9fc8ae-e10f-485c-9127-327755bbdd17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "465570"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_use[df_use['result'] == 'WRONG'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4OWm-cixIu6",
        "outputId": "843e54f8-b0e9-477a-e819-dae4eba8c21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "493095"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_use = df_use.reset_index(drop=True)\n",
        "df_use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ss__PPQ0zOr-",
        "outputId": "400fe684-e5df-43c6-f03e-15c70f54016b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        avg_cr  o_cr  x_cr  curriculum_id  type  problem_cr   result\n",
              "0           63    65    57             17     0    0.171439  CORRECT\n",
              "1           63    65    57              7     2   -2.632940    WRONG\n",
              "2           63    65    57              6     0   -1.111420    WRONG\n",
              "3           63    65    57             10     0   -0.832890  CORRECT\n",
              "4           63    65    57              9     2   -1.317680  CORRECT\n",
              "...        ...   ...   ...            ...   ...         ...      ...\n",
              "958660      63    69    58              9     0    0.978203    WRONG\n",
              "958661      63    69    58              9     2   -0.869958    WRONG\n",
              "958662      63    69    58              9     0    0.019666    WRONG\n",
              "958663      63    69    58              9     0   -0.019859    WRONG\n",
              "958664      63    69    58              9     2   -2.121800    WRONG\n",
              "\n",
              "[958665 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2428a4f-fc00-4037-94f1-f757786ee63b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>type</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.171439</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.632940</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.111420</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.832890</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.317680</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958660</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.978203</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958661</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.869958</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958662</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.019666</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958663</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.019859</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958664</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.121800</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>958665 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2428a4f-fc00-4037-94f1-f757786ee63b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2428a4f-fc00-4037-94f1-f757786ee63b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2428a4f-fc00-4037-94f1-f757786ee63b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "sLIQy9_SSxTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "YbqmorAfK34R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        " \n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        " \n",
        "    student_values = self.df.iloc[:,0:3].values\n",
        "    problem_discrete_values = self.df.iloc[:,3:5].values\n",
        "    problem_conti_values = self.df.iloc[:,5].values\n",
        "\n",
        "    asign = lambda t: 0 if t=='WRONG' else 1\n",
        "    y = list(map(asign, self.df.iloc[:,6].values))\n",
        " \n",
        "    self.student_values = torch.tensor(student_values, dtype=torch.int64)\n",
        "    self.problem_discrete_values = torch.tensor(problem_discrete_values, dtype=torch.int64)\n",
        "    self.problem_conti_values = torch.tensor(problem_conti_values).float()\n",
        "    self.y = torch.tensor(y, dtype=torch.int64)\n",
        " \n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "   \n",
        "  def __getitem__(self,idx):\n",
        "    return self.student_values[idx], self.problem_discrete_values[idx], self.problem_conti_values[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "zrbPXPcu2NKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_num = int(len(df_use) * 0.9)\n",
        "train_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQTP4_450Kgm",
        "outputId": "a545540a-e505-495f-a1d8-c2e53f03a6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "862798"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_use) - train_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_e4462O0RYb",
        "outputId": "9a84dee7-bf03-4d47-9242-420e7f69c635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95867"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_percent = df_use.sample(frac=0.9)\n",
        "df_percent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sJhrSwpa1psq",
        "outputId": "95faeb47-c665-4552-a849-e328529aa79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        avg_cr  o_cr  x_cr  curriculum_id  type  problem_cr   result\n",
              "529900      66    68    62             36     0   -2.052670  CORRECT\n",
              "887113      68    69    64             60     0    0.017024    WRONG\n",
              "119665      77    81    69             58     0    0.879703  CORRECT\n",
              "742497      68    74    64             25     2   -0.804968    WRONG\n",
              "327229      60    62    50             15     0   -0.008645    WRONG\n",
              "...        ...   ...   ...            ...   ...         ...      ...\n",
              "865995      67    69    57             13     0   -0.692013  CORRECT\n",
              "536381      68    69    61             18     0    0.869124    WRONG\n",
              "524432      76    79    70             36     0    0.552105  CORRECT\n",
              "953095      60    64    48             16     0   -1.001050    WRONG\n",
              "258309      64    66    58             34     0    1.437060    WRONG\n",
              "\n",
              "[862798 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d5d5941-7516-4b71-a8a4-c64a517c2c58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>type</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>529900</th>\n",
              "      <td>66</td>\n",
              "      <td>68</td>\n",
              "      <td>62</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.052670</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887113</th>\n",
              "      <td>68</td>\n",
              "      <td>69</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0.017024</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119665</th>\n",
              "      <td>77</td>\n",
              "      <td>81</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0.879703</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742497</th>\n",
              "      <td>68</td>\n",
              "      <td>74</td>\n",
              "      <td>64</td>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.804968</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327229</th>\n",
              "      <td>60</td>\n",
              "      <td>62</td>\n",
              "      <td>50</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.008645</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865995</th>\n",
              "      <td>67</td>\n",
              "      <td>69</td>\n",
              "      <td>57</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.692013</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536381</th>\n",
              "      <td>68</td>\n",
              "      <td>69</td>\n",
              "      <td>61</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.869124</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524432</th>\n",
              "      <td>76</td>\n",
              "      <td>79</td>\n",
              "      <td>70</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0.552105</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953095</th>\n",
              "      <td>60</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.001050</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258309</th>\n",
              "      <td>64</td>\n",
              "      <td>66</td>\n",
              "      <td>58</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>1.437060</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>862798 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d5d5941-7516-4b71-a8a4-c64a517c2c58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d5d5941-7516-4b71-a8a4-c64a517c2c58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d5d5941-7516-4b71-a8a4-c64a517c2c58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_rest = df_use.loc[~df_use.index.isin(df_percent.index)]\n",
        "df_rest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "CNVPYcZ21mO5",
        "outputId": "daad7667-5567-48a6-d664-529ac59233dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        avg_cr  o_cr  x_cr  curriculum_id  type  problem_cr   result\n",
              "27          63    65    57             35     0    0.872802  CORRECT\n",
              "70          63    65    57             37     0   -0.797001  CORRECT\n",
              "97          63    65    57             33     2   -0.580580    WRONG\n",
              "99          63    65    57             34     2    0.355650  CORRECT\n",
              "111         63    65    57             34     2   -0.853011    WRONG\n",
              "...        ...   ...   ...            ...   ...         ...      ...\n",
              "958583      63    69    58             63     0    0.353224    WRONG\n",
              "958593      63    69    58             36     0   -0.549843    WRONG\n",
              "958618      63    69    58             18     0    0.137893    WRONG\n",
              "958619      63    69    58             17     0    0.740803  CORRECT\n",
              "958636      63    69    58             17     0    0.849925    WRONG\n",
              "\n",
              "[95867 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b0aae93-842c-4957-9d79-93ca8af25e62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>type</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0.872802</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.797001</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.580580</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>34</td>\n",
              "      <td>2</td>\n",
              "      <td>0.355650</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>34</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.853011</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958583</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0.353224</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958593</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.549843</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958618</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.137893</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958619</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.740803</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958636</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.849925</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>95867 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b0aae93-842c-4957-9d79-93ca8af25e62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b0aae93-842c-4957-9d79-93ca8af25e62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b0aae93-842c-4957-9d79-93ca8af25e62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = MyDataset(df_percent)\n",
        "test_ds = MyDataset(df_rest)"
      ],
      "metadata": {
        "id": "bbx8TV7ZNANj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = MyDataset(df_2022)"
      ],
      "metadata": {
        "id": "diAoQpJOI9ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Vqz0wWNE3c",
        "outputId": "10b77c7e-1159-4621-fa9b-a6590d4db719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "862798"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbV3h5uT2l2_",
        "outputId": "e8be1539-a766-4226-be8d-7acc76a1f05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1306890"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4PiiRruOR_2",
        "outputId": "13613cb2-f57d-4d33-8784-6234829ca12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([73, 75, 65]), tensor([25,  0]), tensor(-0.0739), tensor(1))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YsNuiJFS-bi",
        "outputId": "80dba81f-7abf-4e9c-d77c-28b18be36f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[66, 68, 62],\n",
              "         [68, 69, 64],\n",
              "         [77, 81, 69],\n",
              "         [68, 74, 64],\n",
              "         [60, 62, 50]]), tensor([[36,  0],\n",
              "         [60,  0],\n",
              "         [58,  0],\n",
              "         [25,  2],\n",
              "         [15,  0]]), tensor([-2.0527,  0.0170,  0.8797, -0.8050, -0.0086]), tensor([1, 0, 1, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "WRgMCDgsVu1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=2)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "Wlgu40kPVwZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEQynHwRV86U",
        "outputId": "c4e9387e-5492-4a17-99ed-1cddd093bed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3371"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 정의"
      ],
      "metadata": {
        "id": "C2DtKIiSWDwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "goSdrkKJ3BRL",
        "outputId": "a1303b46-f83e-41b4-c6dd-5ded94165257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        avg_cr  o_cr  x_cr  curriculum_id  type  problem_cr   result\n",
              "0           63    65    57             17     0    0.171439  CORRECT\n",
              "1           63    65    57              7     2   -2.632940    WRONG\n",
              "2           63    65    57              6     0   -1.111420    WRONG\n",
              "3           63    65    57             10     0   -0.832890  CORRECT\n",
              "4           63    65    57              9     2   -1.317680  CORRECT\n",
              "...        ...   ...   ...            ...   ...         ...      ...\n",
              "958660      63    69    58              9     0    0.978203    WRONG\n",
              "958661      63    69    58              9     2   -0.869958    WRONG\n",
              "958662      63    69    58              9     0    0.019666    WRONG\n",
              "958663      63    69    58              9     0   -0.019859    WRONG\n",
              "958664      63    69    58              9     2   -2.121800    WRONG\n",
              "\n",
              "[958665 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c182acbd-4ee1-40ff-b4a2-0fff64fdc3f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_cr</th>\n",
              "      <th>o_cr</th>\n",
              "      <th>x_cr</th>\n",
              "      <th>curriculum_id</th>\n",
              "      <th>type</th>\n",
              "      <th>problem_cr</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.171439</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.632940</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.111420</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.832890</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63</td>\n",
              "      <td>65</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.317680</td>\n",
              "      <td>CORRECT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958660</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.978203</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958661</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.869958</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958662</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.019666</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958663</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.019859</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958664</th>\n",
              "      <td>63</td>\n",
              "      <td>69</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.121800</td>\n",
              "      <td>WRONG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>958665 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c182acbd-4ee1-40ff-b4a2-0fff64fdc3f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c182acbd-4ee1-40ff-b4a2-0fff64fdc3f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c182acbd-4ee1-40ff-b4a2-0fff64fdc3f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module) :\n",
        "    def __init__(self, score_range=100, curriculum_id=321, type_count=3):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        self.embedding1 = nn.Embedding(score_range, 30)\n",
        "        self.embedding2 = nn.Embedding(score_range, 30)\n",
        "        self.embedding3 = nn.Embedding(score_range, 30)\n",
        "        self.embedding4 = nn.Embedding(curriculum_id, 50)\n",
        "        self.embedding5 = nn.Embedding(type_count, 10)\n",
        "\n",
        "        self.layers1 = nn.Sequential(\n",
        "            nn.Linear(180, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.layers2 = nn.Sequential(\n",
        "            nn.Linear(256, 256),\n",
        "            nn.BatchNorm1d(256)\n",
        "        )\n",
        "        \n",
        "        self.layers3 = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2, x3, x4, x5, x6):\n",
        "        student_1 = self.embedding1(x1)\n",
        "        student_1 = torch.squeeze(student_1, 1)\n",
        "\n",
        "        student_2 = self.embedding2(x2)\n",
        "        student_2 = torch.squeeze(student_2, 1)\n",
        "\n",
        "        student_3 = self.embedding3(x3)\n",
        "        student_3 = torch.squeeze(student_3, 1)\n",
        "\n",
        "        problem_1 = self.embedding4(x4)\n",
        "        problem_1 = torch.squeeze(problem_1, 1)\n",
        "\n",
        "        problem_2 = self.embedding5(x5)\n",
        "        problem_2 = torch.squeeze(problem_2, 1)\n",
        "\n",
        "        st_pr = torch.cat((student_1, student_2, student_3, problem_1, problem_2, x6), 1)\n",
        "        \n",
        "        st_pr = self.layers1(st_pr)\n",
        "        identity = st_pr\n",
        "        st_pr = self.layers2(st_pr)\n",
        "        st_pr += identity\n",
        "        st_pr = self.layers3(st_pr)\n",
        "        return st_pr"
      ],
      "metadata": {
        "id": "H988sI0aPXOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oIxdTyfZJob",
        "outputId": "b1c56b5a-a2f2-4e47-8269-749d1553e130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = MyModel().to(device)\n",
        "test_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE_aW5pZZeCh",
        "outputId": "19c0162d-b5e1-4dcc-febb-b6aacc1e7df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (embedding1): Embedding(100, 30)\n",
              "  (embedding2): Embedding(100, 30)\n",
              "  (embedding3): Embedding(100, 30)\n",
              "  (embedding4): Embedding(321, 50)\n",
              "  (embedding5): Embedding(3, 10)\n",
              "  (layers1): Sequential(\n",
              "    (0): Linear(in_features=180, out_features=256, bias=True)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layers2): Sequential(\n",
              "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layers3): Sequential(\n",
              "    (0): ReLU()\n",
              "    (1): Linear(in_features=256, out_features=32, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=32, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "RG84iFYU2VuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device) # criterion (loss func)도 device 위에서\n",
        "optimizer = torch.optim.Adam(test_model.parameters(), lr=0.001) # 보통 Adam의 learning rate로 0.001 사용"
      ],
      "metadata": {
        "id": "l48GApJdDqtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        input1, input2, input3, labels = data\n",
        "        print(input1.shape)\n",
        "\n",
        "        x1, x2, x3 = torch.split(input1, [1,1,1], dim=1)\n",
        "        x4, x5 = torch.split(input2, [1,1], dim=1)\n",
        "        input3 = torch.unsqueeze(input3, 1)\n",
        "        input3 = input3.expand(input3.shape[0], 30)\n",
        "\n",
        "        x1, x2, x3, x4, x5, input3, labels = x1.to(device), x2.to(device), x3.to(device), x4.to(device), x5.to(device), input3.to(device), labels.to(device)\n",
        "\n",
        "        output = test_model.forward(x1, x2, x3, x4, x5, input3)\n",
        "        #print(output)\n",
        "\n",
        "        loss = criterion(output, labels)  # -> cross entropy 식에 넣을때 이런 형태로 넣으면됨 (outputs, targets의 차원을 맞출 필요가 없음)\n",
        "        print(loss.item())\n",
        "\n",
        "        print(output.max(1)[1]) # 예측한 클래스\n",
        "        print(labels) # 실제 클래스\n",
        "        correct = (output.max(1)[1] == labels).sum().item() # 맞게 예측한 클래스 개수\n",
        "        print(correct)\n",
        "\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvAEkuJ98Vku",
        "outputId": "abd7d46d-cbc4-436f-8dbe-636c850097e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 3])\n",
            "0.5157414078712463\n",
            "tensor([1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
            "        1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
            "        0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
            "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
            "        0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
            "        0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
            "        1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
            "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
            "        0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
            "        0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
            "        1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
            "        0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
            "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "        1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
            "        0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
            "        0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
            "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "        1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
            "        0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
            "        1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
            "        1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
            "186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_train_loss = []\n",
        "seq_test_loss = []\n",
        "seq_train_acc = []\n",
        "seq_test_acc = []"
      ],
      "metadata": {
        "id": "DMO1TzPXEj2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    print(f'\\n[ Train epoch: {epoch+1} ]')\n",
        "\n",
        "    test_model.train() # train은 항상 이걸 지정하고 시작! - Dropout, Batch Normalization 등의 효과를 적용하고 진행하기 위함\n",
        "\n",
        "    running_loss = 0.0\n",
        "    batch_losses = []\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for batch_idx, data in enumerate(train_dataloader):\n",
        "        input1, input2, input3, targets = data\n",
        "        x1, x2, x3 = torch.split(input1, [1,1,1], dim=1)\n",
        "        x4, x5 = torch.split(input2, [1,1], dim=1)\n",
        "        input3 = torch.unsqueeze(input3, 1)\n",
        "        input3 = input3.expand(input3.shape[0], 30)\n",
        "        x1, x2, x3, x4, x5, input3, targets = x1.to(device), x2.to(device), x3.to(device), x4.to(device), x5.to(device), input3.to(device), targets.to(device)\n",
        "        \n",
        "        # DL 학습 기본 코드\n",
        "        optimizer.zero_grad() # gradient 초기화\n",
        "        outputs = test_model.forward(x1, x2, x3, x4, x5, input3) # 현재 batch의 inputs을 모델에 넣어 outputs 추출 (확률값)\n",
        "        loss = criterion(outputs, targets) # 추출한 outputs와 원래 label인 targets 사이 loss 계산\n",
        "        loss.backward() # 계산한 loss 기반으로 gradient 값 계산\n",
        "        optimizer.step() # weight parameter update\n",
        "\n",
        "        total += targets.size(0) # batch 데이터 개수 더하기\n",
        "        running_loss += loss.item()\n",
        "        batch_losses.append(loss.item())\n",
        "        \n",
        "        _, predicted = outputs.max(1) # 확률값 가장 높게 나타난 클래스\n",
        "        correct += (predicted == targets).sum().item() # 현재 batch 내에서 알맞게 분류한 이미지 개수 더하기\n",
        "        \n",
        "        if batch_idx % 1000 == 999:\n",
        "            print(f'\\nCurrent batch: {str(batch_idx+1)}')\n",
        "            print(f'Average train loss of recent 1000 batches: {running_loss / 1000}') # 이렇게 출력하는 것이 꼭 필요한 것은 아니지만, 중간중간 확인을 위해 매우 권장\n",
        "            running_loss = 0.0\n",
        "\n",
        "    avg_loss = sum(batch_losses) / len(batch_losses)\n",
        "    seq_train_loss.append(avg_loss)\n",
        "    seq_train_acc.append(100*correct/total)\n",
        "    print('\\nTotal train accuarcy:', 100. * correct / total) # 전체 데이터 개수에서 맞게 예측한 비율\n",
        "    print('Total train loss:', avg_loss)"
      ],
      "metadata": {
        "id": "iLWMmGBfRtjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "    print(f'\\n[ Test epoch: {epoch+1} ]')\n",
        "\n",
        "    test_model.eval() # eval은 항상 이걸 지정하고 시작! - Dropout, Batch Normalization 등의 효과를 적용하지 않기 위함!\n",
        "                   # ex. evaluation 할때는 Dropout 없이 지금까지 학습한 모든 node를 활용해서 진행해야됨\n",
        "\n",
        "    loss = 0\n",
        "    batch_losses = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad(): # gradient update 안함 - eval과 torch.no_grad는 하나의 세트\n",
        "        for batch_idx, (inputs1, inputs2, inputs3, targets) in enumerate(test_dataloader):\n",
        "            input1, input2, input3, targets = data\n",
        "            x1, x2, x3 = torch.split(input1, [1,1,1], dim=1)\n",
        "            x4, x5 = torch.split(input2, [1,1], dim=1)\n",
        "            input3 = torch.unsqueeze(input3, 1)\n",
        "            input3 = input3.expand(input3.shape[0], 30)\n",
        "            x1, x2, x3, x4, x5, input3, targets = x1.to(device), x2.to(device), x3.to(device), x4.to(device), x5.to(device), input3.to(device), targets.to(device)\n",
        "\n",
        "            outputs = test_model.forward(x1, x2, x3, x4, x5, input3)\n",
        "            loss = criterion(outputs, targets)\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "            total += targets.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    avg_loss = sum(batch_losses) / len(batch_losses)\n",
        "    seq_test_loss.append(avg_loss)\n",
        "    seq_test_acc.append(100 * correct / total)\n",
        "    print('\\nTest accuarcy:', 100. * correct / total)\n",
        "    print('Test average loss:', avg_loss)"
      ],
      "metadata": {
        "id": "CnibXe8gEnp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "tYVz9R1XEvo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch = 50"
      ],
      "metadata": {
        "id": "8pBUg8vyEyYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 연습 삼아 5 epoch만 진행\n",
        "# 실제로 훈련할때는 올바른 epoch 설정 필요\n",
        "\n",
        "for epoch in range(0, num_epoch):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    if (epoch+1) % 5 == 0:\n",
        "      torch.save(test_model.state_dict(), f'./test_model_epoch_{epoch+1}.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtNxrSHhEvOh",
        "outputId": "91527535-e2c6-4113-891a-668771570069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ Train epoch: 1 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.6076019988656044\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5901608240008355\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.588298358976841\n",
            "\n",
            "Total train accuarcy: 68.01603619850765\n",
            "Total train loss: 0.5940357384608146\n",
            "\n",
            "[ Test epoch: 1 ]\n",
            "\n",
            "Test accuarcy: 73.828125\n",
            "Test average loss: 0.5395489931106567\n",
            "\n",
            "[ Train epoch: 2 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5834205373525619\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5839688819050789\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5820503778457642\n",
            "\n",
            "Total train accuarcy: 68.89561635516077\n",
            "Total train loss: 0.5831082077275324\n",
            "\n",
            "[ Test epoch: 2 ]\n",
            "\n",
            "Test accuarcy: 72.265625\n",
            "Test average loss: 0.5394011735916138\n",
            "\n",
            "[ Train epoch: 3 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5814637433290482\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5781311160326004\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5803535323143005\n",
            "\n",
            "Total train accuarcy: 69.18166245169785\n",
            "Total train loss: 0.5797960121583529\n",
            "\n",
            "[ Test epoch: 3 ]\n",
            "\n",
            "Test accuarcy: 75.0\n",
            "Test average loss: 0.5374722480773926\n",
            "\n",
            "[ Train epoch: 4 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5767088332176209\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5774522834420204\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5783262652158737\n",
            "\n",
            "Total train accuarcy: 69.39005421894812\n",
            "Total train loss: 0.5773681530397959\n",
            "\n",
            "[ Test epoch: 4 ]\n",
            "\n",
            "Test accuarcy: 74.609375\n",
            "Test average loss: 0.531761109828949\n",
            "\n",
            "[ Train epoch: 5 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5747882024049759\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5757985805273056\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5760481281280517\n",
            "\n",
            "Total train accuarcy: 69.53759744459306\n",
            "Total train loss: 0.575320615696999\n",
            "\n",
            "[ Test epoch: 5 ]\n",
            "\n",
            "Test accuarcy: 76.953125\n",
            "Test average loss: 0.5332286953926086\n",
            "\n",
            "[ Train epoch: 6 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5732820360362529\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5737423095107078\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5735100093185902\n",
            "\n",
            "Total train accuarcy: 69.69487643689484\n",
            "Total train loss: 0.5735322381650189\n",
            "\n",
            "[ Test epoch: 6 ]\n",
            "\n",
            "Test accuarcy: 74.609375\n",
            "Test average loss: 0.5240641236305237\n",
            "\n",
            "[ Train epoch: 7 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5705561003684998\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5720321162045002\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.572984106272459\n",
            "\n",
            "Total train accuarcy: 69.82572977684232\n",
            "Total train loss: 0.5717890751588172\n",
            "\n",
            "[ Test epoch: 7 ]\n",
            "\n",
            "Test accuarcy: 74.609375\n",
            "Test average loss: 0.5256253480911255\n",
            "\n",
            "[ Train epoch: 8 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5680842581689358\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5703998037576675\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5719032767415047\n",
            "\n",
            "Total train accuarcy: 69.93711158347608\n",
            "Total train loss: 0.5701709431680364\n",
            "\n",
            "[ Test epoch: 8 ]\n",
            "\n",
            "Test accuarcy: 73.4375\n",
            "Test average loss: 0.5218073725700378\n",
            "\n",
            "[ Train epoch: 9 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5680418265163898\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5689201342463494\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5697570440471172\n",
            "\n",
            "Total train accuarcy: 70.0685444333436\n",
            "Total train loss: 0.568814580852856\n",
            "\n",
            "[ Test epoch: 9 ]\n",
            "\n",
            "Test accuarcy: 73.4375\n",
            "Test average loss: 0.5250463485717773\n",
            "\n",
            "[ Train epoch: 10 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5650113401710987\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5672308399379253\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5677906030416489\n",
            "\n",
            "Total train accuarcy: 70.16404766816798\n",
            "Total train loss: 0.5671285265491398\n",
            "\n",
            "[ Test epoch: 10 ]\n",
            "\n",
            "Test accuarcy: 74.21875\n",
            "Test average loss: 0.5142369866371155\n",
            "\n",
            "[ Train epoch: 11 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5649116462171078\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5650840888917447\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5664428971111775\n",
            "\n",
            "Total train accuarcy: 70.27774751448196\n",
            "Total train loss: 0.5657890319594358\n",
            "\n",
            "[ Test epoch: 11 ]\n",
            "\n",
            "Test accuarcy: 74.21875\n",
            "Test average loss: 0.5203192234039307\n",
            "\n",
            "[ Train epoch: 12 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5625564273297786\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5645062769055367\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.56440065741539\n",
            "\n",
            "Total train accuarcy: 70.37116451359414\n",
            "Total train loss: 0.5642629930347832\n",
            "\n",
            "[ Test epoch: 12 ]\n",
            "\n",
            "Test accuarcy: 74.21875\n",
            "Test average loss: 0.5244319438934326\n",
            "\n",
            "[ Train epoch: 13 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5610944534540176\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5620287638604641\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5650501787662506\n",
            "\n",
            "Total train accuarcy: 70.47709892697944\n",
            "Total train loss: 0.5627765489487434\n",
            "\n",
            "[ Test epoch: 13 ]\n",
            "\n",
            "Test accuarcy: 76.953125\n",
            "Test average loss: 0.5105374455451965\n",
            "\n",
            "[ Train epoch: 14 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5595656792521477\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5621188689470291\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5627825699448585\n",
            "\n",
            "Total train accuarcy: 70.55695539396244\n",
            "Total train loss: 0.5615423901856953\n",
            "\n",
            "[ Test epoch: 14 ]\n",
            "\n",
            "Test accuarcy: 75.78125\n",
            "Test average loss: 0.5103663802146912\n",
            "\n",
            "[ Train epoch: 15 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5578952350318432\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5614401375353336\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5601307862699032\n",
            "\n",
            "Total train accuarcy: 70.66810539662818\n",
            "Total train loss: 0.5601204913523953\n",
            "\n",
            "[ Test epoch: 15 ]\n",
            "\n",
            "Test accuarcy: 75.0\n",
            "Test average loss: 0.5100588798522949\n",
            "\n",
            "[ Train epoch: 16 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5567872362136841\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.558461904168129\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5604362605810166\n",
            "\n",
            "Total train accuarcy: 70.75816123820408\n",
            "Total train loss: 0.5587157401883683\n",
            "\n",
            "[ Test epoch: 16 ]\n",
            "\n",
            "Test accuarcy: 76.5625\n",
            "Test average loss: 0.5062400698661804\n",
            "\n",
            "[ Train epoch: 17 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5549798336327076\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5587104210853576\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.559657129496336\n",
            "\n",
            "Total train accuarcy: 70.84103115677134\n",
            "Total train loss: 0.5575713505910433\n",
            "\n",
            "[ Test epoch: 17 ]\n",
            "\n",
            "Test accuarcy: 75.390625\n",
            "Test average loss: 0.510415256023407\n",
            "\n",
            "[ Train epoch: 18 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5547581118345261\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5560640894472599\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5570280905365944\n",
            "\n",
            "Total train accuarcy: 70.89399836346398\n",
            "Total train loss: 0.5563269571040088\n",
            "\n",
            "[ Test epoch: 18 ]\n",
            "\n",
            "Test accuarcy: 74.609375\n",
            "Test average loss: 0.5166651010513306\n",
            "\n",
            "[ Train epoch: 19 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5528999259471893\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5562173526287079\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5552967582046986\n",
            "\n",
            "Total train accuarcy: 71.01152297525029\n",
            "Total train loss: 0.5549782520760701\n",
            "\n",
            "[ Test epoch: 19 ]\n",
            "\n",
            "Test accuarcy: 77.34375\n",
            "Test average loss: 0.5101752877235413\n",
            "\n",
            "[ Train epoch: 20 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.550157910823822\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5551933906674386\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5544949769377708\n",
            "\n",
            "Total train accuarcy: 71.09103173628127\n",
            "Total train loss: 0.5537241376390517\n",
            "\n",
            "[ Test epoch: 20 ]\n",
            "\n",
            "Test accuarcy: 76.953125\n",
            "Test average loss: 0.4946174621582031\n",
            "\n",
            "[ Train epoch: 21 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5499200539588929\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5534830801784992\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5538620470166207\n",
            "\n",
            "Total train accuarcy: 71.14631698265411\n",
            "Total train loss: 0.5526345351600959\n",
            "\n",
            "[ Test epoch: 21 ]\n",
            "\n",
            "Test accuarcy: 75.390625\n",
            "Test average loss: 0.5007057189941406\n",
            "\n",
            "[ Train epoch: 22 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5475208415687084\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5524476968646049\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.553448898255825\n",
            "\n",
            "Total train accuarcy: 71.22165327226071\n",
            "Total train loss: 0.5515155236680724\n",
            "\n",
            "[ Test epoch: 22 ]\n",
            "\n",
            "Test accuarcy: 75.0\n",
            "Test average loss: 0.4918130040168762\n",
            "\n",
            "[ Train epoch: 23 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5480367910861969\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5491755498051644\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5527276427745819\n",
            "\n",
            "Total train accuarcy: 71.28458804957823\n",
            "Total train loss: 0.5504691417971905\n",
            "\n",
            "[ Test epoch: 23 ]\n",
            "\n",
            "Test accuarcy: 77.34375\n",
            "Test average loss: 0.48864248394966125\n",
            "\n",
            "[ Train epoch: 24 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5465697649121285\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.550961833178997\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.550427303224802\n",
            "\n",
            "Total train accuarcy: 71.36189467291301\n",
            "Total train loss: 0.5493608490980828\n",
            "\n",
            "[ Test epoch: 24 ]\n",
            "\n",
            "Test accuarcy: 77.34375\n",
            "Test average loss: 0.48228445649147034\n",
            "\n",
            "[ Train epoch: 25 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5464439338743686\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.548014366865158\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5504959017336368\n",
            "\n",
            "Total train accuarcy: 71.430276843479\n",
            "Total train loss: 0.5483670614834392\n",
            "\n",
            "[ Test epoch: 25 ]\n",
            "\n",
            "Test accuarcy: 76.953125\n",
            "Test average loss: 0.48581692576408386\n",
            "\n",
            "[ Train epoch: 26 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5443670212626457\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5476273890733719\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5486951165795326\n",
            "\n",
            "Total train accuarcy: 71.46713367439423\n",
            "Total train loss: 0.5474024461783984\n",
            "\n",
            "[ Test epoch: 26 ]\n",
            "\n",
            "Test accuarcy: 78.515625\n",
            "Test average loss: 0.47912198305130005\n",
            "\n",
            "[ Train epoch: 27 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.542390463680029\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5467995426654816\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5484464032351971\n",
            "\n",
            "Total train accuarcy: 71.53748617868841\n",
            "Total train loss: 0.5463651595236604\n",
            "\n",
            "[ Test epoch: 27 ]\n",
            "\n",
            "Test accuarcy: 78.125\n",
            "Test average loss: 0.4870598018169403\n",
            "\n",
            "[ Train epoch: 28 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5426609607934951\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5444682631194592\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5482555997371673\n",
            "\n",
            "Total train accuarcy: 71.6105044286148\n",
            "Total train loss: 0.5454578007745728\n",
            "\n",
            "[ Test epoch: 28 ]\n",
            "\n",
            "Test accuarcy: 77.34375\n",
            "Test average loss: 0.47927361726760864\n",
            "\n",
            "[ Train epoch: 29 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5416486003100872\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5444187037944793\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5459662933647632\n",
            "\n",
            "Total train accuarcy: 71.65396767261862\n",
            "Total train loss: 0.5444291338337808\n",
            "\n",
            "[ Test epoch: 29 ]\n",
            "\n",
            "Test accuarcy: 79.296875\n",
            "Test average loss: 0.4682804346084595\n",
            "\n",
            "[ Train epoch: 30 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.540356351196766\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5445220744609833\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5446417612731457\n",
            "\n",
            "Total train accuarcy: 71.64434780794578\n",
            "Total train loss: 0.5436372188760067\n",
            "\n",
            "[ Test epoch: 30 ]\n",
            "\n",
            "Test accuarcy: 76.5625\n",
            "Test average loss: 0.4733292758464813\n",
            "\n",
            "[ Train epoch: 31 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5393708382844925\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5426586659550667\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5444873804152012\n",
            "\n",
            "Total train accuarcy: 71.76511767528437\n",
            "Total train loss: 0.5427535780545548\n",
            "\n",
            "[ Test epoch: 31 ]\n",
            "\n",
            "Test accuarcy: 77.734375\n",
            "Test average loss: 0.47999483346939087\n",
            "\n",
            "[ Train epoch: 32 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5388770913183689\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5410027274489403\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5453830118477344\n",
            "\n",
            "Total train accuarcy: 71.77508524590924\n",
            "Total train loss: 0.5419899537668706\n",
            "\n",
            "[ Test epoch: 32 ]\n",
            "\n",
            "Test accuarcy: 76.953125\n",
            "Test average loss: 0.4771895408630371\n",
            "\n",
            "[ Train epoch: 33 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5373225752413273\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5404258577525616\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5440830557048321\n",
            "\n",
            "Total train accuarcy: 71.84381512242726\n",
            "Total train loss: 0.5409468169631041\n",
            "\n",
            "[ Test epoch: 33 ]\n",
            "\n",
            "Test accuarcy: 78.515625\n",
            "Test average loss: 0.4860096871852875\n",
            "\n",
            "[ Train epoch: 34 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5366968004703522\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5414929395914078\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5416797991394997\n",
            "\n",
            "Total train accuarcy: 71.85424630098818\n",
            "Total train loss: 0.5403580727473949\n",
            "\n",
            "[ Test epoch: 34 ]\n",
            "\n",
            "Test accuarcy: 76.171875\n",
            "Test average loss: 0.48513302206993103\n",
            "\n",
            "[ Train epoch: 35 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5358181838393211\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5395469398200512\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.542429370880127\n",
            "\n",
            "Total train accuarcy: 71.89504379935975\n",
            "Total train loss: 0.5393880337291074\n",
            "\n",
            "[ Test epoch: 35 ]\n",
            "\n",
            "Test accuarcy: 77.34375\n",
            "Test average loss: 0.4737519323825836\n",
            "\n",
            "[ Train epoch: 36 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5365631389319897\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5387873874604702\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5397137585580349\n",
            "\n",
            "Total train accuarcy: 71.93178472829098\n",
            "Total train loss: 0.5388629962873898\n",
            "\n",
            "[ Test epoch: 36 ]\n",
            "\n",
            "Test accuarcy: 76.953125\n",
            "Test average loss: 0.4660709798336029\n",
            "\n",
            "[ Train epoch: 37 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5334915060102939\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5395509813129902\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5396559086740017\n",
            "\n",
            "Total train accuarcy: 71.97374124650266\n",
            "Total train loss: 0.5380147521024075\n",
            "\n",
            "[ Test epoch: 37 ]\n",
            "\n",
            "Test accuarcy: 76.171875\n",
            "Test average loss: 0.4835706651210785\n",
            "\n",
            "[ Train epoch: 38 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5344762469530105\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5374553762972355\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5387803025543689\n",
            "\n",
            "Total train accuarcy: 72.03632831786814\n",
            "Total train loss: 0.5373287971933529\n",
            "\n",
            "[ Test epoch: 38 ]\n",
            "\n",
            "Test accuarcy: 78.125\n",
            "Test average loss: 0.4602935016155243\n",
            "\n",
            "[ Train epoch: 39 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.533707179158926\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5361385431289672\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5393770557940006\n",
            "\n",
            "Total train accuarcy: 72.046179986509\n",
            "Total train loss: 0.5365790047726197\n",
            "\n",
            "[ Test epoch: 39 ]\n",
            "\n",
            "Test accuarcy: 78.515625\n",
            "Test average loss: 0.4688844680786133\n",
            "\n",
            "[ Train epoch: 40 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5323083884119988\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5364025725722313\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5376378217637539\n",
            "\n",
            "Total train accuarcy: 72.0950906237613\n",
            "Total train loss: 0.5359193016958675\n",
            "\n",
            "[ Test epoch: 40 ]\n",
            "\n",
            "Test accuarcy: 77.34375\n",
            "Test average loss: 0.4747965931892395\n",
            "\n",
            "[ Train epoch: 41 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5320930857658386\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5358893852233887\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5372102701961994\n",
            "\n",
            "Total train accuarcy: 72.1442330649816\n",
            "Total train loss: 0.5353773856368131\n",
            "\n",
            "[ Test epoch: 41 ]\n",
            "\n",
            "Test accuarcy: 79.296875\n",
            "Test average loss: 0.4517633616924286\n",
            "\n",
            "[ Train epoch: 42 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5305124631226062\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.534731009721756\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5376074302494526\n",
            "\n",
            "Total train accuarcy: 72.16590673599151\n",
            "Total train loss: 0.5347167309721723\n",
            "\n",
            "[ Test epoch: 42 ]\n",
            "\n",
            "Test accuarcy: 75.78125\n",
            "Test average loss: 0.46261104941368103\n",
            "\n",
            "[ Train epoch: 43 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5309347306191922\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5339177188277244\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5365518900752068\n",
            "\n",
            "Total train accuarcy: 72.21446966729177\n",
            "Total train loss: 0.5339469825503593\n",
            "\n",
            "[ Test epoch: 43 ]\n",
            "\n",
            "Test accuarcy: 78.515625\n",
            "Test average loss: 0.45760199427604675\n",
            "\n",
            "[ Train epoch: 44 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5298030795454979\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5337864131331443\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5356669374108315\n",
            "\n",
            "Total train accuarcy: 72.27381148310496\n",
            "Total train loss: 0.5333539070343271\n",
            "\n",
            "[ Test epoch: 44 ]\n",
            "\n",
            "Test accuarcy: 76.953125\n",
            "Test average loss: 0.46259355545043945\n",
            "\n",
            "[ Train epoch: 45 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5303942802548408\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5327187240719795\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5349522479772568\n",
            "\n",
            "Total train accuarcy: 72.25422404780726\n",
            "Total train loss: 0.5330247885835733\n",
            "\n",
            "[ Test epoch: 45 ]\n",
            "\n",
            "Test accuarcy: 76.953125\n",
            "Test average loss: 0.469264954328537\n",
            "\n",
            "[ Train epoch: 46 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5279994493126869\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5319893113970756\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5347540387511254\n",
            "\n",
            "Total train accuarcy: 72.35077040048772\n",
            "Total train loss: 0.5323555241597225\n",
            "\n",
            "[ Test epoch: 46 ]\n",
            "\n",
            "Test accuarcy: 77.34375\n",
            "Test average loss: 0.46343767642974854\n",
            "\n",
            "[ Train epoch: 47 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5269743580818176\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5321804147362709\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.533899228990078\n",
            "\n",
            "Total train accuarcy: 72.30707535251588\n",
            "Total train loss: 0.5316239192891778\n",
            "\n",
            "[ Test epoch: 47 ]\n",
            "\n",
            "Test accuarcy: 74.609375\n",
            "Test average loss: 0.47925034165382385\n",
            "\n",
            "[ Train epoch: 48 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5276839025616645\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5307194770574569\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5336499584317207\n",
            "\n",
            "Total train accuarcy: 72.37429850324177\n",
            "Total train loss: 0.5311792231355779\n",
            "\n",
            "[ Test epoch: 48 ]\n",
            "\n",
            "Test accuarcy: 78.125\n",
            "Test average loss: 0.4695541560649872\n",
            "\n",
            "[ Train epoch: 49 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5260892997384071\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5301684212386608\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.533409083455801\n",
            "\n",
            "Total train accuarcy: 72.39875382186793\n",
            "Total train loss: 0.5305339021150169\n",
            "\n",
            "[ Test epoch: 49 ]\n",
            "\n",
            "Test accuarcy: 75.0\n",
            "Test average loss: 0.47258007526397705\n",
            "\n",
            "[ Train epoch: 50 ]\n",
            "\n",
            "Current batch: 1000\n",
            "Average train loss of recent 1000 batches: 0.5263837284743785\n",
            "\n",
            "Current batch: 2000\n",
            "Average train loss of recent 1000 batches: 0.5308260154426098\n",
            "\n",
            "Current batch: 3000\n",
            "Average train loss of recent 1000 batches: 0.5316507690548897\n",
            "\n",
            "Total train accuarcy: 72.4440714976159\n",
            "Total train loss: 0.5301449093928998\n",
            "\n",
            "[ Test epoch: 50 ]\n",
            "\n",
            "Test accuarcy: 75.390625\n",
            "Test average loss: 0.47250187397003174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jvqUvb6SE_yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(num_epoch), seq_train_loss, label=\"Train loss\")\n",
        "plt.plot(range(num_epoch), seq_test_loss, label=\"Test loss\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mF7X9YLkE3R4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f41065d0-ba97-4aa4-dc45-c6c49ba0476d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(num_epoch), seq_train_acc, label=\"Train Accuracy\")\n",
        "plt.plot(range(num_epoch), seq_test_acc, label=\"Test Accuracy\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PD70MVZ8E40-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "5b080d99-8cc8-4be6-b781-ff5f2ac9197d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 활용\n",
        "\n",
        "ex) 70 85 65 vs 70 90 60\n",
        "\n",
        "단원 = 17 (확률의 곱셈정리), type = 0, correct rate = 0.1\n",
        "\n",
        "0 = wrong, 1 = correct\n"
      ],
      "metadata": {
        "id": "ezVNrT80amsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.Tensor([[70],[70]]).int().to(device)\n",
        "x2 = torch.Tensor([[85],[90]]).int().to(device)\n",
        "x3 = torch.Tensor([[65],[60]]).int().to(device)\n",
        "x4 = torch.Tensor([[17],[17]]).int().to(device)\n",
        "x5 = torch.Tensor([[0],[0]]).int().to(device)\n",
        "x6 = torch.Tensor([[0.1], [0.1]]).to(device)\n",
        "x6 = x6.expand(x6.shape[0], 30)"
      ],
      "metadata": {
        "id": "ynjRYhIKbfZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = test_model(x1, x2, x3, x4, x5, x6)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tdCKcYoanzy",
        "outputId": "ecda74fd-0f31-4053-bb77-254672d72fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0892, -0.5989],\n",
              "        [ 0.2084,  0.0356]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.functional.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ8ZOUGCcncv",
        "outputId": "bcb04961-8c31-4d7d-8414-76b2daa9efb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8440, 0.1560],\n",
              "        [0.5431, 0.4569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "더 쉬운 문제?"
      ],
      "metadata": {
        "id": "6U34PSOven87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x6 = torch.Tensor([[1.0], [1.0]]).to(device)\n",
        "x6 = x6.expand(x6.shape[0], 30)"
      ],
      "metadata": {
        "id": "7tOJyF3Geptc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = test_model(x1, x2, x3, x4, x5, x6)\n",
        "torch.nn.functional.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFhKYoUOesa0",
        "outputId": "f62f0d2d-5f9e-46fa-c134-e78b75d5423a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4532, 0.5468],\n",
              "        [0.2076, 0.7924]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다른 단원에서는? 35 (수열의 극한)"
      ],
      "metadata": {
        "id": "c0rPILy5e6JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x4 = torch.Tensor([[35],[35]]).int().to(device)\n",
        "outputs = test_model(x1, x2, x3, x4, x5, x6)\n",
        "torch.nn.functional.softmax(outputs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doqolsEse7_Q",
        "outputId": "26d6eec5-46ec-4a2d-b6c3-9db2c56d7246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6951, 0.3049],\n",
              "        [0.8106, 0.1894]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    }
  ]
}